{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Premature optimization is the root of all evil\" - Donald Knuth\n",
    "\n",
    "It’s usually more important that your code runs correctly according to the business requirements and that other team members can understand it rather than it being the most efficient solution.\n",
    "\n",
    "The actual time-saver might be elsewhere. For example, having the ability to quickly extend your code with new features to meet user needs.\n",
    "\n",
    "Sometimes, the return on investment in performance optimizations just isn’t worth the effort. If you only run your code once or twice, or if it takes longer to improve the code than execute it, then what’s the point?\n",
    "\n",
    "Code will often become faster just as a result of fixing the bugs and refactoring. One of the creators of Erlang once said:\n",
    "\n",
    "Make it work, then make it beautiful, then if you really, really have to, make it fast. 90 percent of the time, if you make it beautiful, it will already be fast. So really, just make it beautiful! (Source)\n",
    "\n",
    "— Joe Armstrong\n",
    "\n",
    "Optimize performance as a final step if it's necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software profiling is the process of collecting and analyzing various metrics of a running program to identify performance bottlenecks.\n",
    "\n",
    "Software profiling can help tell you whether optimizing the code is necessary and, if so, which parts of the code to focus on.\n",
    "\n",
    "Note: A performance profiler is a valuable tool for identifying hot spots in existing code, but it won’t tell you how to write efficient code from the start.\n",
    "\n",
    "It’s often the choice of the underlying algorithm or data structure that can make the biggest difference. Even when you throw the most advanced hardware available on the market at some computational problem, an algorithm with a poor time or space complexity may never finish in a reasonable time.\n",
    "\n",
    "These bottlenecks can happen due to a number of reasons: including excessive memory use, inefficient CPU utilization, or a suboptimal data layout, which will result in frequent cache misses that increase latency.\n",
    "\n",
    "The bottlenecks might lie not in the underlying code’s execution time but in network communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of python profilers. You should pick the right tool for the job.\n",
    "- Timers like the `time` and `timeit` standard library modules, or the `codetiming` third-party package\n",
    "- Deterministic profilers like `profile`, `cProfile`, and `line_profiler`\n",
    "- Statistical profilers like `Pyinstrument` and the Linux `perf` profiler\n",
    "- Scalene\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `time` for measuring the exact execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time module is versatile and quick to set up, making it suitable for temporary checks. It’ll give you a faithful impression of runtime in real-world conditions, taking into account factors like the current system load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeper()\n",
      " Real time: 1.75 seconds\n",
      " CPU time: 0.00 seconds\n",
      "\n",
      "spinlock()\n",
      " Real time: 1.95 seconds\n",
      " CPU time: 1.95 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ask the OS to suspend the current thread of execution for 1.75 secs\n",
    "# during this time the function remains dormant without occupying the CPU\n",
    "def sleeper():\n",
    "    time.sleep(1.75)\n",
    "\n",
    "# perform busy waiting, wasting CPU cycles without doing any useful work\n",
    "def spinlock():\n",
    "    for _ in range(100_000_000):\n",
    "        pass\n",
    "\n",
    "\n",
    "for function in sleeper, spinlock:\n",
    "    # get wall-clock time and CPU time\n",
    "    t1 = time.perf_counter(), time.process_time()\n",
    "    function()\n",
    "    t2 = time.perf_counter(), time.process_time()\n",
    "    print(f\"{function.__name__}()\")\n",
    "    print(f\" Real time: {t2[0] - t1[0]:.2f} seconds\")\n",
    "    print(f\" CPU time: {t2[1] - t1[1]:.2f} seconds\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `timeit` for benchmarking code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `timeit` module accounts from factors such as system load, garbage collection or other processes that might be running concurrently that might skew timing results. The timeit module helps to mitigate these factors, providing a more accurate measure of code execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284 ms ± 7.33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Average time is 0.28 seconds'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "# A recursive function that calculates the nth element of the Fibonacci sequence\n",
    "def fib(n):\n",
    "    return n if n < 2 else fib(n - 2) + fib(n - 1)\n",
    "\n",
    "# repeat 100 times\n",
    "iterations = 100\n",
    "total_time = timeit(\"fib(30)\", number=iterations, globals=globals())\n",
    "\n",
    "# with magic command\n",
    "# %timeit fib(30)\n",
    "\n",
    "# average to average out random fluctuations in execution time that may come from other processes running on your computer.\n",
    "f\"Average time is {total_time / iterations:.2f} seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `cProfile` for collecting detailed runtime statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cProfiler` is a deterministic profiler, which can help you answer questions like how many times a particular function was called or how much total time was spent inside that function. A deterministic profiler can give you reproducible results under the same conditions because it traces all function calls in your program.\n",
    "\n",
    "You can use cProfile against your whole program in the command line or profile a narrow code fragment programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(35) = 9227465\n",
      "         29860736 function calls (34 primitive calls) in 7.329 seconds\n",
      "\n",
      "   Ordered by: call count\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "29860703/1    7.329    0.000    7.329    7.329 1786731988.py:5(fib)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:444(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:465(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:535(write)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:529(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1059(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1113(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:613(send)\n",
      "        1    0.000    0.000    0.000    0.000 cProfile.py:50(create_stats)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:107(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:117(init)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:136(load_stats)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:203(schedule)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cProfile import Profile\n",
    "from pstats import SortKey, Stats\n",
    "\n",
    "\n",
    "def fib(n):\n",
    "    return n if n < 2 else fib(n - 2) + fib(n - 1)\n",
    "\n",
    "\n",
    "with Profile() as profile:\n",
    "    print(f\"{fib(35) = }\")\n",
    "    (Stats(profile).strip_dirs().sort_stats(SortKey.CALLS).print_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
