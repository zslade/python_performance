{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Premature optimization is the root of all evil\" - Donald Knuth\n",
    "\n",
    "It’s usually more important that your code runs correctly according to the business requirements and that other team members can understand it rather than it being the most efficient solution.\n",
    "\n",
    "The actual time-saver might be elsewhere. For example, having the ability to quickly extend your code with new features to meet user needs.\n",
    "\n",
    "Sometimes, the return on investment in performance optimizations just isn’t worth the effort. If you only run your code once or twice, or if it takes longer to improve the code than execute it, then what’s the point?\n",
    "\n",
    "Code will often become faster just as a result of fixing the bugs and refactoring. One of the creators of Erlang once said:\n",
    "\n",
    "Make it work, then make it beautiful, then if you really, really have to, make it fast. 90 percent of the time, if you make it beautiful, it will already be fast. So really, just make it beautiful! (Source)\n",
    "\n",
    "— Joe Armstrong\n",
    "\n",
    "Optimize performance as a final step if it's necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software profiling is the process of collecting and analyzing various metrics of a running program to identify performance bottlenecks.\n",
    "\n",
    "Software profiling can help tell you whether optimizing the code is necessary and, if so, which parts of the code to focus on.\n",
    "\n",
    "Note: A performance profiler is a valuable tool for identifying hot spots in existing code, but it won’t tell you how to write efficient code from the start.\n",
    "\n",
    "It’s often the choice of the underlying algorithm or data structure that can make the biggest difference. Even when you throw the most advanced hardware available on the market at some computational problem, an algorithm with a poor time or space complexity may never finish in a reasonable time.\n",
    "\n",
    "These bottlenecks can happen due to a number of reasons: including excessive memory use, inefficient CPU utilization, or a suboptimal data layout, which will result in frequent cache misses that increase latency.\n",
    "\n",
    "The bottlenecks might lie not in the underlying code’s execution time but in network communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of python profilers. You should pick the right tool for the job.\n",
    "- Timers like the `time` and `timeit` standard library modules, or the `codetiming` third-party package\n",
    "- Deterministic profilers like `profile`, `cProfile`, and `line_profiler`\n",
    "- Statistical profilers like `Pyinstrument` and the Linux `perf` profiler\n",
    "- Scalene\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `time` for measuring the exact execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time module is versatile and quick to set up, making it suitable for temporary checks. It’ll give you a faithful impression of runtime in real-world conditions, taking into account factors like the current system load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeper()\n",
      " Real time: 1.75 seconds\n",
      " CPU time: 0.00 seconds\n",
      "\n",
      "spinlock()\n",
      " Real time: 1.95 seconds\n",
      " CPU time: 1.95 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ask the OS to suspend the current thread of execution for 1.75 secs\n",
    "# during this time the function remains dormant without occupying the CPU\n",
    "def sleeper():\n",
    "    time.sleep(1.75)\n",
    "\n",
    "# perform busy waiting, wasting CPU cycles without doing any useful work\n",
    "def spinlock():\n",
    "    for _ in range(100_000_000):\n",
    "        pass\n",
    "\n",
    "\n",
    "for function in sleeper, spinlock:\n",
    "    # get wall-clock time and CPU time\n",
    "    t1 = time.perf_counter(), time.process_time()\n",
    "    function()\n",
    "    t2 = time.perf_counter(), time.process_time()\n",
    "    print(f\"{function.__name__}()\")\n",
    "    print(f\" Real time: {t2[0] - t1[0]:.2f} seconds\")\n",
    "    print(f\" CPU time: {t2[1] - t1[1]:.2f} seconds\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<code object sleeper at 0x7f9dee8df9d0, file \"/var/folders/nd/c3xr518x3txg5kcqp1h7zwc80000gp/T/ipykernel_43716/1048847327.py\", line 3>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleeper.__code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
